<!--
# Chapter 4. The Operating System

## The role of the operating system

The operating system underpins the entire operation of the modern computer.

### Abstraction of hardware
The fundamental operation of the operating system (OS) is to abstract the hardware to the programmer and user. The operating system provides generic interfaces to services provided by the underlying hardware.

In a world without operating systems, every programmer would need to know the most intimate details of the underlying hardware to get anything to run. Worse still, their programs would not run on other hardware, even if that hardware has only slight differences.

### Multitasking
We expect modern computers to do many different things at once, and we need some way to arbitrate between all the different programs running on the system. It is the operating systems job to allow this to happen seamlessly.

The operating system is responsible for resource management within the system. Many tasks will be competing for the resources of the system as it runs, including processor time, memory, disk and user input. The job of the operating system is to arbitrate these resources to the multiple tasks and allow them access in an orderly fashion. You have probably experienced when this fails as it usually ends up with your computer crashing (the famous "blue screen of death" for example).

### Standardised Interfaces
Programmers want to write programs that will run on as many different hardware platforms as possible. By having operating system support for standardised interfaces, programmers can get this functionality.

For example, if the function to open a file on one system is open(), on another is open_file() and on yet another openf() programmers will have the dual problem of having to remember what each system does and their programs will not work on multiple systems.

The Portable Operating System Interface (POSIX)[9] is a very important standard implemented by UNIX type operating systems. Microsoft Windows has similar proprietary standards.
-->

# 第四章。操作系統


## 操作系統的角色


操作系統支撐著現代計算機的整個操作。


### 硬件的抽象

操作系統(OS)的基本操作是將硬件抽象給程序員和用戶。操作系統為基礎硬件提供的服務提供通用接口。


在一個沒有操作系統的世界裡，每個程序員都需要知道底層硬件的最私密細節才能運行任何東西。更糟糕的是，他們的程序不會在其他硬件上運行，即使這些硬件只有細微的差別。


### 多任務

我們希望現代計算機能同時做許多不同的事情，我們需要某種方法來仲裁系統上運行的所有不同程序。允許這種情況無縫發生是操作系統的工作。


操作系統負責系統內的資源管理。許多任務將在系統運行時爭奪系統的資源，包括處理器時間、內存、磁碟和用戶輸入。操作系統的工作是將這些資源仲裁給多個任務，並允許它們有序地訪問。您可能已經經歷過這種失敗，因為它通常會導致您的計算機崩潰(例如著名的“藍屏死亡”)。


### 標準化接口

程序員希望編寫能夠在儘可能多的不同硬件平台上運行的程序。通過對標準化接口的操作系統支持，程序員可以獲得這種功能。


例如，如果在一個系統上打開文件的函數是open()，那麼在另一個系統上打開文件的函數就是open_file()，而在另一個openf()上，程序員將面臨雙重問題:必須記住每個系統的功能，並且他們的程序不能在多個系統上工作。


可移植操作系統接口(POSIX)[9]是由UNIX類型操作系統實現的一個非常重要的標準。微軟Windows也有類似的專有標準。

<!--
### Security
On multi-user systems, security is very important. As the arbitrator of access to the system the operating system is responsible for ensuring that only those with the correct permissions can access resources.

For example if a file is owned by one user, another user should not be allowed to open and read it. However there also need to be mechanisms to share that file safely between the users should they want it.

Operating systems are large and complex programs, and often security issues will be found. Often a virus or worm will take advantage of these bugs to access resources it should not be allowed to, such as your files or network connection; to fight them you must install patches or updates provided by your operating system vendor.

### Performance
As the operating system provides so many services to the computer, its performance is critical. Many parts of the operating system run extremely frequently, so even an overhead of just a few processor cycles can add up to a big decrease in overall system performance.

The operating system needs to exploit the features of the underlying hardware to make sure it is getting the best possible performance for the operations, and consequently systems programmers need to understand the intimate details of the architecture they are building for.

In many cases the systems programmers job is about deciding on policies for the system. Often the case that the side effects of making one part of the operating system run faster will make another part run slower or less efficiently. Systems programmers need to understand all these trade offs when they are building their operating system.

> [9] The X comes from Unix, from which the standard grew. Today, POSIX is the same thing as the Single UNIX Specification Version 3 or ISO/IEC 9945:2002. This is a free standard, available online.
> 
> Once upon a time, the Single UNIX specification and the POSIX Standards were separate entities. The Single UNIX specification was released by a consortium called the "Open Group", and was freely available as per their requirements. The latest version is The Single Unix Specification Version 3.
> 
> The IEEE POSIX standards were released as IEEE Std 1003.[insert various years, revisions here], and were not freely available. The latest version is IEEE 1003.1-2001 and is equivalent to the Single Unix Specification Version 3.
> 
> Thus finally the two separate standards were merged into what is known as the Single UNIX Specification Version 3, which is also standardised by the ISO under ISO/IEC 9945:2002. This happened early in 2002. So when people talk about POSIX, SUS3 or ISO/IEC 9945:2002 they all mean the same thing!
-->

### 安全

在多用戶系統中，安全性非常重要。作為系統訪問的仲裁者，操作系統負責確保只有具有正確權限的用戶才能訪問資源。


例如，如果一個文件屬於一個用戶，那麼不應該允許另一個用戶打開並讀取它。然而，還需要有機制在用戶之間安全地共享文件，如果他們需要的話。


操作系統是又大又複雜的程序，經常會出現安全問題。通常，病毒或蠕蟲會利用這些漏洞訪問不應該被允許訪問的資源，例如文件或網絡連接;要對抗它們，您必須安裝由操作系統供應商提供的補丁或更新。


### 性能

由於操作系統為計算機提供了如此多的服務，其性能至關重要。操作系統的許多部分都非常頻繁地運行，因此即使是幾個處理器週期的開銷也會導致系統整體性能的大幅下降。

操作系統需要利用底層硬件的特性，以確保為操作獲得儘可能好的性能，因此系統程序員需要瞭解他們所構建的體系結構的詳細信息。

在許多情況下，系統程序員的工作是決定系統的策略。通常情況下，使操作系統的一個部分運行得更快的副作用會使另一個部分運行得更慢或效率更低。系統程序員在構建操作系統時需要瞭解所有這些權衡。


> [9] X來自Unix，標準就是從Unix發展而來的。今天，POSIX與單獨的UNIX規範版本3或ISO/IEC 9945:2002相同。這是一個免費的標準，可以在網上找到。
>
> 曾經，單個UNIX規範和POSIX標準是獨立的實體。單個UNIX規範是由一個名為“開放組”的聯盟發佈的，並且可以根據它們的需求免費獲得。最新的版本是單個Unix規範版本3。
> IEEE POSIX標準以IEEE Std 1003發佈。[插入不同的年份，此處修改]，並且不能免費獲得。最新的版本是IEEE 1003.1-2001，相當於單個Unix規範版本3。
> 因此，>最終將這兩個獨立的標準合併到所謂的單一UNIX規範版本3中，該版本也被ISO/IEC 9945:2002標準體系標準化。這發生在2002年初。所以當人們談論POSIX、SUS3或ISO/IEC 9945:2002時，他們的意思都是一樣的!

<!--
## Operating System Organisation

The operating system is roughly organised as in the figure below.

> Figure 4.1. The Operating System

![](http://www.bottomupcs.com/chapter03/figures/kernel.png)

> The organisation of the kernel. Processes the kernel is running live in userspace, and the kernel talks both directly to hardware and through drivers.


### The Kernel
The kernel is the operating system. As the figure illustrates, the kernel communicates to hardware both directly and through drivers.

Just as the kernel abstracts the hardware to user programs, drivers abstract hardware to the kernel. For example there are many different types of graphic card, each one with slightly different features. As long as the kernel exports an API, people who have access to the specifications for the hardware can write drivers to implement that API. This way the kernel can access many different types of hardware.

The kernel is generally what we called privileged. As you will learn, the hardware has important roles to play in running multiple tasks and keeping the system secure, but these rules do not apply to the kernel. We know that the kernel must handle programs that crash (remember it is the operating systems job arbitrate between multiple programs running on the same system, and there is no guarantee that they will behave), but if any internal part of the operating system crashes chances are the entire system will become useless. Similarly security issues can be exploited by user processes to escalate themselves to the privilege level of the kernel; at that point they can access any part of the system completely unchecked.

### Monolithic v Microkernels
One debate that is often comes up surrounding operating systems is whether the kernel should be a microkernel or monolithic.

The monolithic approach is the most common, as taken by most common Unixes (such as Linux). In this model the core privileged kernel is large, containing hardware drivers, file system accesses controls, permissions checking and services such as Network File System (NFS).

Since the kernel is always privileged, if any part of it crashes the whole system has the potential to comes to a halt. If one driver has a bug it can overwrite any memory in the system with no problems, ultimately causing the system to crash.

A microkernel architecture tries to minimise this possibility by making the privileged part of the kernel as small as possible. This means that most of the system runs as unprivileged programs, limiting the harm that any one crashing component can influence. For example, drivers for hardware can run in separate processes, so if one goes astray it can not overwrite any memory but that allocated to it.

Whilst this sounds like the most obvious idea, the problem comes back two main issues

1. Performance is decreased. Talking between many different components can decrease performance.
2. It is slightly more difficult for the programmer.

Both of these criticisms come because to keep separation between components most microkernels are implemented with a message passing based system, commonly referred to as inter-process communication or IPC. Communicating between individual components happens via discrete messages which must be bundled up, sent to the other component, unbundled, operated upon, re-bundled up and sent back, and then unbundled again to get the result.

This is a lot of steps for what might be a fairly simple request from a foreign component. Obviously one request might make the other component do more requests of even more components, and the problem can multiply. Slow message passing implementations were largely responsible for the poor performance of early microkernel systems, and the concepts of passing messages are slightly harder for programmers to program for. The enhanced protection from having components run separately was not sufficient to overcome these hurdles in early microkernel systems, so they fell out of fashion.

In a monolithic kernel calls between components are simple function calls, as all programmers are familiar with.

There is no definitive answer as to which is the best organisation, and it has started many arguments in both academic and non-academic circles. Hopefully as you learn more about operating systems you will be able to make up your own mind!
-->
## 操作系統組織


### 操作系統大致如下圖所示。


> 圖4.1。操作系統


![](http://www.bottomupcs.com/chapter03/figures/kernel.png)


內核的組織。進程內核正在用戶空間中運行，內核直接與硬件和通過驅動程序進行對話。


### 內核

內核是操作系統。如圖所示，內核直接和硬件通過驅動程序進行通信。

正如內核將硬件抽象為用戶程序一樣，驅動程序也將硬件抽象為內核。例如，有許多不同類型的圖形卡，每一個都有略微不同的功能。只要內核導出API，訪問硬件規範的人就可以編寫驅動程序來實現該API。這樣內核就可以訪問許多不同類型的硬件。


內核通常就是我們所說的特權。正如您將瞭解到的，硬件在運行多個任務和保持系統安全方面扮演著重要的角色，但是這些規則並不適用於內核。我們知道,內核必須處理程序崩潰(記住,這是操作系統工作在同一個系統上運行多個程序之間的仲裁,並不能保證他們會表現),但是如果任何內部操作系統崩潰的一部分可能是整個系統將變得毫無用處。類似地，用戶進程可以利用安全問題將自己提升到內核的特權級別;在這一點上，他們可以完全不受約束地訪問系統的任何部分。


### 單片機v微內核

圍繞操作系統經常出現的一個爭論是內核應該是微內核還是單片內核。


整體方法是最常見的方法，大多數常見的unix(如Linux)都採用這種方法。在這個模型中，核心特權內核是大型的，包含硬件驅動程序、文件系統訪問控制、權限檢查和網絡文件系統(NFS)等服務。


由於內核總是有特權的，如果內核的任何部分崩潰，整個系統都有可能停止。如果一個驅動程序有錯誤，它可以覆蓋系統中的任何內存，沒有問題，最終導致系統崩潰。


微內核體系結構通過使內核的特權部分儘可能小來儘量減少這種可能性。這意味著大多數系統運行為非特權程序，限制了任何一個崩潰組件可能造成的危害。例如，硬件驅動程序可以在單獨的進程中運行，所以如果一個進程出錯，它就不能覆蓋任何內存，只能覆蓋分配給它的內存。


雖然這聽起來是最明顯的想法，但問題回到了兩個主要問題


1. 性能卻降低了。在許多不同組件之間進行通信會降低性能。
2. 對於程序員來說稍微困難一點。


這兩種批評都是因為為了保持組件之間的分離，大多數微內核都是通過基於消息傳遞的系統實現的，通常稱為進程間通信或IPC。各個組件之間的通信是通過離散的消息進行的，這些消息必須打包、發送到其他組件、分離、操作、重新打包和發送，然後再重新打包以獲得結果。


對於來自外部組件的一個相當簡單的請求，這是許多步驟。顯然，一個請求可能會使另一個組件對更多的組件發出更多的請求，這個問題可能會成倍增加。較慢的消息傳遞實現在很大程度上導致了早期微內核系統的糟糕性能，而傳遞消息的概念對程序員來說要編程稍微困難一些。在早期的微內核系統中，防止組件單獨運行的增強保護不足以克服這些障礙，因此它們不再流行。


在組件間的單片內核調用是簡單的函數調用，這是所有程序員都熟悉的。


至於哪家機構是最好的，目前還沒有明確答案，它在學術界和非學術界引發了許多爭論。希望隨著你對操作系統的瞭解越來越多，你能自己做決定!

<!--
### Modules
The Linux kernel implements a module system, where drivers can loaded into the running kernel "on the fly" as they are required. This is good in that drivers, which make up a large part of operating system code, are not loaded for devices that are not present in the system. Someone who wants to make the most generic kernel possible (i.e. runs on lots of different hardware, such as RedHat or Debian) can include most drivers as modules which are only loaded if the system it is running on has the hardware available.

However, the modules are loaded directly in the privileged kernel and operate at the same privilege level as the rest of the kernel, so the system is still considered a monolithic kernel.

### Virtualisation
Closely related to kernel is the concept of virtualisation of hardware. Modern computers are very powerful, and often it is useful to not thing of them as one whole system but split a single physical computer up into separate "virtual" machines. Each of these virtual machines looks for all intents and purposes as a completely separate machine, although physically they are all in the same box, in the same place.

> Figure 4.2. The Operating System

![](http://www.bottomupcs.com/chapter03/figures/virtual.png)

> Some different virtualisation methods.

This can be organised in many different ways. In the simplest case, a small virtual machine monitor can run directly on the hardware and provide an interface to the guest operating systems running on top. This VMM is often often called a hypervisor (from the word "supervisor")[10]. In fact, the operating system on top may have no idea that the hypervisor is even there at all, as the hypervisor presents what appears to be a complete system. It intercepts operations between the guest operating system and hardware and only presents a subset of the system resources to each.

This is often used on large machines (with many CPUs and much RAM) to implement partitioning. This means the machine can be split up into smaller virtual machines. Often you can allocate more resources to running systems on the fly, as requirements dictate. The hypervisors on many large IBM machines are actually quite complicated affairs, with many millions of lines of code. It provides a multitude of system management services.

Another option is to have the operating system aware of the underlying hypervisor, and request system resources through it. This is sometimes referred to as paravirtualisation due to its halfway nature. This is similar to the way early versions of the Xen system works and is a compromise solution. It hopefully provides better performance since the operating system is explicitly asking for system resources from the hypervisor when required, rather than the hypervisor having to work things out dynamically.

Finally, you may have a situation where an application running on top of the existing operating system presents a virtualised system (including CPU, memory, BIOS, disk, etc) which a plain operating system can run on. The application converts the requests to hardware through to the underlying hardware via the existing operating system. This is similar to how VMWare works. This approach has many overheads, as the application process has to emulate an entire system and convert everything to requests from the underlying operating system. However, this lets you emulate an entirely different architecture all together, as you can dynamically translate the instructions from one processor type to another (as the Rosetta system does with Apple software which moved from the PowerPC processor to Intel based processors).

Performance is major concern when using any of these virtualisation techniques, as what was once fast operations directly on hardware need to make their way through layers of abstraction.

Intel have discussed hardware support for virtualisation soon to be coming in their latest processors. These extensions work by raising a special exception for operations that might require the intervention of a virtual machine monitor. Thus the processor looks the same as a non-virtualised processor to the application running on it, but when that application makes requests for resources that might be shared between other guest operating systems the virtual machine monitor can be invoked.

This provides superior performance because the virtual machine monitor does not need to monitor every operation to see if it is safe, but can wait until the processor notifies that something unsafe has happened.
-->

### 模組

Linux內核實現了一個模組系統，其中驅動程序可以根據需要“動態”加載到正在運行的內核中。這很好，因為驅動程序(構成操作系統代碼的很大一部分)不會為系統中不存在的設備加載。那些想要使最通用的內核成為可能的人(例如，在許多不同的硬件上運行，如RedHat或Debian)可以將大多數驅動程序包含在模組中，這些模組只有在運行它的系統有可用的硬件時才會加載。


但是，這些模組直接裝載在特權內核中，並且與內核的其他部分在相同的特權級別上操作，因此系統仍然被認為是一個整體內核。


### 虛擬化

與內核密切相關的是硬件虛擬化的概念。現代計算機是非常強大的，通常將它們作為一個整體系統，而將單個物理計算機分割成單獨的“虛擬”計算機是非常有用的。每個虛擬機都將所有意圖和目的視為一個完全獨立的機器，儘管它們在物理上都位於相同的框中，位於相同的位置。


> 圖4.2。操作系統


![](http://www.bottomupcs.com/chapter03/figures/virtual.png)


> 一些不同的虛擬化方法。


這可以用許多不同的方式來組織。在最簡單的情況下，小型虛擬機監視器可以直接在硬件上運行，併為運行在上面的客戶操作系統提供接口。這個VMM通常被稱為一個hypervisor(從“supervisor”這個詞開始)[10]。實際上，上面的操作系統可能根本不知道虛擬機監控程序存在，因為虛擬機監控程序呈現的似乎是一個完整的系統。它攔截客戶操作系統和硬件之間的操作，只向每個操作系統顯示系統資源的子集。


這通常在大型計算機(具有許多cpu和大量RAM)上用於實現分區。這意味著機器可以被分割成更小的虛擬機。通常，您可以根據需要為動態運行的系統分配更多的資源。許多大型IBM機器上的虛擬機監控程序實際上是相當複雜的事情，有數百萬行代碼。它提供多種系統管理服務。


另一種選擇是讓操作系統知道底層管理程序，並通過它請求系統資源。由於半虛擬化的性質，這有時被稱為半虛擬化。這類似於Xen系統的早期版本，是一種折衷的解決方案。希望它能提供更好的性能，因為操作系統在需要時顯式地向hypervisor請求系統資源，而不是由hypervisor動態地解決問題。


最後，您可能遇到這樣一種情況，即在現有操作系統之上運行的應用程序呈現了一個虛擬系統(包括CPU、內存、BIOS、磁碟等)，普通操作系統可以在該系統上運行。應用程序通過現有的操作系統將請求轉換為硬件，再通過底層硬件轉換為底層硬件。這與VMWare的工作原理類似。這種方法有很多開銷，因為應用程序流程必須模擬整個系統，並將所有內容轉換為來自底層操作系統的請求。不過，這讓您可以模擬完全不同的架構，因為您可以動態地將指令從一種處理器類型轉換到另一種處理器類型(就像Rosetta系統使用從PowerPC處理器轉移到基於英特爾處理器的蘋果軟件那樣)。


當使用任何這些虛擬化技術時，性能是主要關注的問題，因為曾經直接在硬件上進行的快速操作需要通過抽象層進行。


英特爾已經討論了在他們最新的處理器中對虛擬化的硬件支持。這些擴展通過為可能需要虛擬機監視器干預的操作引發特殊異常來工作。因此，對於運行在其上的應用程序來說，處理器看起來與非虛擬化處理器相同，但是當該應用程序請求可能在其他客戶操作系統之間共享的資源時，可以調用虛擬機監視器。


這提供了優越的性能，因為虛擬機監視器不需要監視每個操作，以查看它是否安全，但是可以等待處理器通知發生了不安全的事情。

<!--
### Covert Channels
This is a digression, but an interesting security flaw relating to virtualised machines. If the partitioning of the system is not static, but rather dynamic, there is a potential security issue involved.

In a dynamic system, resources are allocated to the operating systems running on top as required. Thus if one is doing particularly CPU intensive operations whilst the other is waiting on data to come from disks, more of the CPU power will be given to the first task. In a static system, each would get 50% an the unused portion would go to waste.

Dynamic allocation actually opens up a communications channel between the two operating systems. Anywhere that two states can be indicated is sufficient to communicate in binary. Imagine both systems are extremely secure, and no information should be able to pass between one and the other, ever. Two people with access could collude to pass information between themselves by writing two programs that try to take large amounts of resources at the same time.

When one takes a large amount of memory there is less available for the other. If both keep track of the maximum allocations, a bit of information can be transferred. Say they make a pact to check every second if they can allocate this large amount of memory. If the target can, that is considered binary 0, and if it can not (the other machine has all the memory), that is considered binary 1. A data rate of one bit per second is not astounding, but information is flowing.

This is called a covert channel, and whilst admittedly far fetched there have been examples of security breaches from such mechanisms. It just goes to show that the life of a systems programmer is never simple!

### Userspace
We call the theoretical place where programs run by the user userspace. Each program runs in userspace, talking to the kernel through system calls (discussed below).

As previously discussed, userspace is unprivileged. User programs can only do a limited range of things, and should never be able to crash other programs, even if they crash themselves.

> [10] In fact, the hypervisor shares much in common with a micro-kernel; both strive to be small layers to present the hardware in a safe fashion to layers above it.
-->

### 秘密通道

這是一個離題，但與虛擬化機器相關的一個有趣的安全缺陷。如果係統的分區不是靜態的，而是動態的，那麼就存在潛在的安全問題。


在動態系統中，根據需要將資源分配給運行在上面的操作系統。因此，如果其中一個正在執行特別密集的CPU操作，而另一個正在等待來自磁碟的數據，那麼更多的CPU能力將用於第一個任務。在靜態系統中，每個人將得到50%的剩餘部分將被浪費掉。


動態分配實際上打開了兩個操作系統之間的通信通道。任何可以指示兩個狀態的地方都足以用二進制進行通信。假設這兩個系統都非常安全，並且任何信息都不應該在其中一個和另一個之間傳遞。兩個有權限的人可以通過編寫兩個程序來相互傳遞信息，這兩個程序試圖同時占用大量資源。


當其中一個占用大量內存時，另一個占用的內存就會減少。如果兩者都跟蹤最大分配，就可以傳遞一點信息。假設他們每秒鐘都要檢查一下是否能分配這麼大的內存。如果目標可以，則認為二進制0，如果不能(另一台機器擁有所有內存)，則認為二進制1。每秒1比特的數據速率並不令人震驚，但信息是流動的。


這就是所謂的秘密渠道，雖然不可否認的是，這種機制中存在安全漏洞的例子。它只是表明，系統程序員的生活從來都不簡單!


### 用戶空間

我們把由用戶空間運行的程序稱為理論空間。每個程序在用戶空間中運行，通過系統調用與內核通信(下面將討論)。


如前所述，用戶空間是無特權的。用戶程序只能做有限的事情，並且永遠不能使其他程序崩潰，即使它們自己崩潰。


實際上，虛擬機監控程序與微內核有許多共同之處;兩者都力求是小的層，以一種安全的方式將硬件呈現到它上面的層。

<!--
## System Calls

### Overview
System calls are how userspace programs interact with the kernel. The general principle behind how they work is described below.

### System call numbers
Each and every system call has a system call number which is known by both the userspace and the kernel. For example, both know that system call number 10 is open(), system call number 11 is read(), etc.

The Application Binary Interface (ABI) is very similar to an API but rather than being for software is for hardware. The API will define which register the system call number should be put in so the kernel can find it when it is asked to do the system call.

### Arguments
System calls are no good without arguments; for example open() needs to tell the kernel exactly what file to open. Once again the ABI will define which registers arguments should be put into for the system call.

### The trap
To actually perform the system call, there needs to be some way to communicate to the kernel we wish to make a system call. All architectures define an instruction, usually called break or something similar, that signals to the hardware we wish to make a system call.

Specifically, this instruction will tell the hardware to modify the instruction pointer to point to the kernels system call handler (when the operating system sets its self up it tells the hardware where its system call handler lives). So once the userspace calls the break instruction, it has lost control of the program and passed it over to the kernel.

The rest of the operation is fairly straight forward. The kernel looks in the predefined register for the system call number, and looks it up in a table to see which function it should call. This function is called, does what it needs to do, and places its return value into another register defined by the ABI as the return register.

The final step is for the kernel to make a jump instruction back to the userspace program, so it can continue off where it left from. The userpsace program gets the data it needs from the return register, and continues happily on its way!

Although the details of the process can get quite hairy, this is basically all their is to a system call.

### libc
Although you can do all of the above by hand for each system call, system libraries usually do most of the work for you. The standard library that deals with system calls on UNIX like systems is libc; we will learn more about its roles in future weeks.
-->

## 系統調用


### 概述

系統調用是用戶空間程序與內核交互的方式。它們工作原理的一般原理如下所述。


系統呼叫號碼

每個系統調用都有一個系統調用號，用戶空間和內核都知道這個號。例如，都知道系統調用10是open()，系統調用11是read()，等等。


應用程序二進制接口(ABI)與API非常相似，但不是用於軟件，而是用於硬件。API將定義應該放入系統調用號的寄存器，以便內核在請求進行系統調用時能夠找到它。


### 參數

沒有參數的系統調用是不好的;例如，open()需要確切地告訴內核要打開什麼文件。ABI將再次為系統調用定義應該放入哪些寄存器參數。


### 陷阱

要實際執行系統調用，需要有某種方式與我們希望進行系統調用的內核通信。所有體系結構都定義了一條指令，通常稱為break或類似的東西，它向我們希望進行系統調用的硬件發出信號。


具體來說，該指令將告訴硬件修改指令指針以指向內核系統調用處理程序(當操作系統設置其自身時，它將告訴硬件系統調用處理程序位於何處)。因此，一旦用戶空間調用break指令，它就失去了對程序的控制，並將其傳遞給內核。


其餘的操作相當直接。內核在預定義的系統調用號寄存器中查找，並在表中查找它應該調用的函數。這個函數被調用，執行它需要執行的操作，並將其返回值放入ABI定義為返回寄存器的另一個寄存器中。


最後一步是內核向用戶空間程序執行跳轉指令，這樣它就可以繼續離開原來的地方。userpsace程序從返回寄存器中獲取所需的數據，並愉快地繼續運行!


儘管這個過程的細節可能會變得很複雜，但這基本上就是系統調用的全部內容。


### libc

儘管您可以為每個系統調用手工完成以上所有工作，但是系統庫通常為您完成大部分工作。在類似UNIX的系統上處理系統調用的標準庫是libc;我們將在未來幾週進一步瞭解它的角色。
<!--
### Analysing a system call
As the system libraries usually deal with making systems call for you, we need to do some low level hacking to illustrate exactly how the system calls work.

We will illustrate how probably the most simple system call, getpid(), works. This call takes no arguments and returns the ID of the currently running program (or process; we'll look more at the process in later weeks).

> Example 4.1. getpid() example
-->

### 分析系統調用

由於系統庫通常為您處理系統調用，我們需要進行一些低級別的黑客工作，以確切地說明系統調用是如何工作的。


我們將演示最簡單的系統調用getpid()是如何工作的。此調用不接受任何參數，並返回當前正在運行的程序(或進程)的ID;我們將在後面幾週進一步研究這個過程)。

> 4.1的例子。getpid()例子

```c
#include <stdio.h>

/* for syscall() */
#include <sys/syscall.h>
#include <unistd.h>

/* system call numbers */
#include <asm/unistd.h>

void function(void)
{
	int pid;

	pid = __syscall(__NR_getpid);
}
```

<!--
We start by writing a small C program which we can start to illustrate the mechanism behind system calls. The first thing to note is that there is a syscall argument provided by the system libraries for directly making system calls. This provides an easy way for programmers to directly make systems calls without having to know the exact assembly language routines for making the call on their hardware. So why do we use getpid() at all? Firstly, it is much clearer to use a symbolic function name in your code. However, more importantly, getpid() may work in very different ways on different systems. For example, on Linux the getpid() call can be cached, so if it is run twice the system library will not take the penalty of having to make an entire system call to find out the same information again.

By convention under Linux, system calls numbers are defined in the asm/unistd.h file from the kernel source. Being in the asm subdirectory, this is different for each architecture Linux runs on. Again by convention, system calls numbers are given a#define name consisting of __NR_. Thus you can see our code will be making the getpid system call, storing the value in pid.

We will have a look at how several architectures implement this code under the hood. We're going to look at real code, so things can get quite hairy. But stick with it -- this is exactly how your system works!

### PowerPC
PowerPC is a RISC architecture common in older Apple computers, and the core of devices such as the latest version of the Xbox.

> Example 4.2. PowerPC system call example
-->

我們從編寫一個小型C程序開始，我們可以開始說明系統調用背後的機制。首先要注意的是，系統庫提供了一個syscall參數，用於直接進行系統調用。這為程序員提供了一種簡單的方法，可以直接進行系統調用，而不必知道在硬件上進行調用的確切彙編語言常式。那麼，我們為什麼要使用getpid()呢?首先，在代碼中使用符號函數名要清楚得多。然而，更重要的是，getpid()可能在不同的系統上以非常不同的方式工作。例如，在Linux上，getpid()調用可以被緩存，因此如果它運行兩次，系統庫就不必再進行一次完整的系統調用來再次查找相同的信息。


按照Linux的慣例，系統調用號是在asm/unistd中定義的。h文件來自內核原代碼。在asm子目錄中，這對於運行Linux的每個體系結構都是不同的。同樣，按照慣例，系統調用號被賦予一個由__NR_組成的#define名稱。因此，您可以看到，我們的代碼將進行getpid系統調用，將值存儲在pid中。


我們將瞭解幾個體系結構如何在底層實現此代碼。我們將學習真正的代碼，所以問題會變得很複雜。但請堅持下去——這正是您的系統工作的方式!

### PowerPC

PowerPC是舊蘋果電腦中常見的RISC架構，也是最新版Xbox等設備的核心。


> 4.2的例子。PowerPC系統調用示例

```c

/* On powerpc a system call basically clobbers the same registers like a
 * function call, with the exception of LR (which is needed for the
 * "sc; bnslr" sequence) and CR (where only CR0.SO is clobbered to signal
 * an error return status).
 */

#define __syscall_nr(nr, type, name, args...)				\
	unsigned long __sc_ret, __sc_err;				\
	{								\
		register unsigned long __sc_0  __asm__ ("r0");		\
		register unsigned long __sc_3  __asm__ ("r3");		\
		register unsigned long __sc_4  __asm__ ("r4");		\
		register unsigned long __sc_5  __asm__ ("r5");		\
		register unsigned long __sc_6  __asm__ ("r6");		\
		register unsigned long __sc_7  __asm__ ("r7");		\
									\
		__sc_loadargs_##nr(name, args);				\
		__asm__ __volatile__					\
			("sc           \n\t"				\
			 "mfcr %0      "				\
			: "=&r" (__sc_0),				\
			  "=&r" (__sc_3),  "=&r" (__sc_4),		\
			  "=&r" (__sc_5),  "=&r" (__sc_6),		\
			  "=&r" (__sc_7)				\
			: __sc_asm_input_##nr				\
			: "cr0", "ctr", "memory",			\
			  "r8", "r9", "r10","r11", "r12");		\
		__sc_ret = __sc_3;					\
		__sc_err = __sc_0;					\
	}								\
	if (__sc_err & 0x10000000)					\
	{								\
		errno = __sc_ret;					\
		__sc_ret = -1;						\
	}								\
	return (type) __sc_ret

#define __sc_loadargs_0(name, dummy...)					\
	__sc_0 = __NR_##name
#define __sc_loadargs_1(name, arg1)					\
	__sc_loadargs_0(name);						\
	__sc_3 = (unsigned long) (arg1)
#define __sc_loadargs_2(name, arg1, arg2)				\
	__sc_loadargs_1(name, arg1);					\
	__sc_4 = (unsigned long) (arg2)
#define __sc_loadargs_3(name, arg1, arg2, arg3)				\
	__sc_loadargs_2(name, arg1, arg2);				\
	__sc_5 = (unsigned long) (arg3)
#define __sc_loadargs_4(name, arg1, arg2, arg3, arg4)			\
	__sc_loadargs_3(name, arg1, arg2, arg3);			\
	__sc_6 = (unsigned long) (arg4)
#define __sc_loadargs_5(name, arg1, arg2, arg3, arg4, arg5)		\
	__sc_loadargs_4(name, arg1, arg2, arg3, arg4);			\
	__sc_7 = (unsigned long) (arg5)

#define __sc_asm_input_0 "0" (__sc_0)
#define __sc_asm_input_1 __sc_asm_input_0, "1" (__sc_3)
#define __sc_asm_input_2 __sc_asm_input_1, "2" (__sc_4)
#define __sc_asm_input_3 __sc_asm_input_2, "3" (__sc_5)
#define __sc_asm_input_4 __sc_asm_input_3, "4" (__sc_6)
#define __sc_asm_input_5 __sc_asm_input_4, "5" (__sc_7)

#define _syscall0(type,name)						\
type name(void)								\
{									\
	__syscall_nr(0, type, name);					\
}

#define _syscall1(type,name,type1,arg1)					\
type name(type1 arg1)							\
{									\
	__syscall_nr(1, type, name, arg1);				\
}

#define _syscall2(type,name,type1,arg1,type2,arg2)			\
type name(type1 arg1, type2 arg2)					\
{									\
	__syscall_nr(2, type, name, arg1, arg2);			\
}

#define _syscall3(type,name,type1,arg1,type2,arg2,type3,arg3)		\
type name(type1 arg1, type2 arg2, type3 arg3)				\
{									\
	__syscall_nr(3, type, name, arg1, arg2, arg3);			\
}

#define _syscall4(type,name,type1,arg1,type2,arg2,type3,arg3,type4,arg4) \
type name(type1 arg1, type2 arg2, type3 arg3, type4 arg4)		\
{									\
	__syscall_nr(4, type, name, arg1, arg2, arg3, arg4);		\
}

#define _syscall5(type,name,type1,arg1,type2,arg2,type3,arg3,type4,arg4,type5,arg5) \
type name(type1 arg1, type2 arg2, type3 arg3, type4 arg4, type5 arg5)	\
{									\
	__syscall_nr(5, type, name, arg1, arg2, arg3, arg4, arg5);	\
}
```
              
<!--
This code snippet from the kernel header file asm/unistd.h shows how we can implement system calls on PowerPC. It looks very complicated, but it can be broken down step by step.

Firstly, jump to the end of the example where the _syscallN macros are defined. You can see there are many macros, each one taking progressively one more argument. We'll concentrate on the most simple version, _syscall0 to start with. It only takes two arguments, the return type of the system call (e.g. a C int or char, etc) and the name of the system call. For getpid this would be done as _syscall0(int,getpid).

Easy so far! We now have to start pulling apart __syscall_nr macro. This is not dissimilar to where we were before, we take the number of arguments as the first parameter, the type, name and then the actual arguments.

The first step is declaring some names for registers. What this essentially does is says __sc_0 refers to r0 (i.e. register 0). The compiler will usually use registers how it wants, so it is important we give it constraints so that it doesn't decide to go using register we need in some ad-hoc manner.

We then call sc_loadargs with the interesting## parameter. That is just a paste command, which gets replaced by the nr variable. Thus for our example it expands to __sc_loadargs_0(name, args);. __sc_loadargs we can see below sets __sc_0 to be the system call number; notice the paste operator again with the __NR_ prefix we talked about, and the variable name that refers to a specific register.

So, all this tricky looking code actually does is puts the system call number in register 0! Following the code through, we can see that the other macros will place the system call arguments into r3 through r7 (you can only have a maximum of 5 arguments to your system call).

Now we are ready to tackle the __asm__ section. What we have here is called inline assembly because it is assembler code mixed right in with source code. The exact syntax is a little to complicated to go into right here, but we can point out the important parts.

Just ignore the __volatile__ bit for now; it is telling the compiler that this code is unpredictable so it shouldn't try and be clever with it. Again we'll start at the end and work backwards. All the stuff after the colons is a way of communicating to the compiler about what the inline assembly is doing to the CPU registers. The compiler needs to know so that it doesn't try using any of these registers in ways that might cause a crash.

But the interesting part is the two assembly statements in the first argument. The one that does all the work is the sc call. That's all you need to do to make your system call!

So what happens when this call is made? Well, the processor is interrupted knows to transfer control to a specific piece of code setup at system boot time to handle interrupts. There are many interrupts; system calls are just one. This code will then look in register 0 to find the system call number; it then looks up a table and finds the right function to jump to to handle that system call. This function receives its arguments in registers 3 - 7.

So, what happens once the system call handler runs and completes? Control returns to the next instruction after the sc, in this case a memory fence instruction. What this essentially says is "make sure everything is committed to memory"; remember how we talked about pipelines in the superscalar architecture? This instruction ensures that everything we think has been written to memory actually has been, and isn't making its way through a pipeline somewhere.

Well, we're almost done! The only thing left is to return the value from the system call. We see that __sc_ret is set from r3 and __sc_err is set from r0. This is interesting; what are these two values all about?

One is the return value, and one is the error value. Why do we need two variables? System calls can fail, just as any other function. The problem is that a system call can return any possible value; we can not say "a negative value indicates failure" since a negative value might be perfectly acceptable for some particular system call.

So our system call function, before returning, ensures its result is in register r3 and any error code is in register r0. We check the error code to see if the top bit is set; this would indicate a negative number. If so, we set the global errno value to it (this is the standard variable for getting error information on call failure) and set the return to be -1. Of course, if a valid result is received we return it directly.

So our calling function should check the return value is not -1; if it is it can check errno to find the exact reason why the call failed.

And that is an entire system call on a PowerPC!
-->

這段代碼來自asm/unistd內核頭文件。h展示了如何在PowerPC上實現系統調用。它看起來很複雜，但可以逐步分解。


首先，跳到示例的結尾，其中定義了_syscallN宏。你可以看到有很多宏，每一個都有一個參數。我們將從最簡單的_syscall0開始。它只接受兩個參數，系統調用的返回類型(例如C int或char，等等)和系統調用的名稱。對於getpid，這將作為_syscall0(int,getpid)來執行。


容易到目前為止!現在我們必須開始分解__syscall_nr宏。這與之前的情況沒有什麼不同，我們將參數的數量作為第一個參數、類型、名稱和實際參數。


第一步是為寄存器聲明一些名稱。這實際上是說__sc_0指的是r0(也就是寄存器0)編譯器通常會按照它想要的方式使用寄存器，所以我們給它一些約束是很重要的，這樣它就不會決定使用我們需要的寄存器了。


然後我們使用有趣的##參數調用sc_loadargs。這只是一個粘貼命令，它被nr變數替換。因此，對於我們的示例，它擴展為__sc_loadargs_0(名稱，args);。我們可以看到下面設置__sc_0為系統調用號;注意粘貼操作符帶有我們討論過的__NR_首碼，以及引用特定寄存器的變數名。


所以，所有這些複雜的代碼實際上是把系統調用號放在寄存器0!按照代碼執行，我們可以看到其他宏將通過r7將系統調用參數放入r3(系統調用最多只能有5個參數)。


現在我們準備處理__asm__部分。我們這裡的代碼叫做內聯程序集，因為它是與原代碼混合在一起的彙編代碼。確切的語法在這裡有點複雜，但我們可以指出重要的部分。


現在就忽略掉這個常量。它告訴編譯器這段代碼是不可預測的，所以它不應該嘗試使用它。我們還是從最後開始，然後往回算。冒號之後的所有內容都是一種向編譯器傳遞內聯程序集對CPU寄存器做什麼的方式。編譯器需要知道，這樣它就不會嘗試以可能導致崩潰的方式使用這些寄存器。


但有趣的是第一個論點中的兩個彙編語句。完成所有工作的是sc調用。這就是您進行系統調用所需要做的全部工作!


那麼當這個調用被調用時會發生什麼呢?處理器被中斷了，它知道在系統啟動時將控制權轉移到特定的代碼設置中以處理中斷。有很多中斷;系統調用只是一個。該代碼將在寄存器0中查找系統調用號;然後，它查找一個表並找到要跳轉到的正確函數來處理該系統調用。這個函數在寄存器3 - 7中接收它的參數。


那麼，當系統調用處理程序運行並完成時會發生什麼呢?控件返回到sc之後的下一條指令，在本例中是一條內存圍欄指令。這基本上是說"確保所有東西都被記住"還記得我們如何討論超標量體系結構中的管道嗎?這條指令確保了我們認為已經寫入內存的所有東西實際上都已經寫入，而不是通過某個地方的管道。


好了，快做完了!剩下的唯一事情就是從系統調用返回值。我們看到__sc_ret是從r3中設置的，__sc_err是從r0中設置的。這是有趣的;這兩個值是什麼意思?


一個是返回值，一個是錯誤值。為什麼我們需要兩個變數?系統調用可能會失敗，就像其他任何函數一樣。問題是系統調用可以返回任何可能的值;我們不能說“負數表示失敗”，因為負數對於某些特定的系統調用可能完全可以接受。


所以我們的系統調用函數，在返回之前，確保它的結果在寄存器r3中，任何錯誤代碼都在寄存器r0中。我們檢查錯誤代碼，看看頂部的位是否設置;這表示一個負數。如果是，我們將全局errno值設置為它(這是在調用失敗時獲取錯誤信息的標準變數)，並將返回值設置為-1。當然，如果收到一個有效的結果，我們會直接返回它。


所以我們的調用函數應該檢查返回值是否為-1;如果是，它可以檢查errno以找到調用失敗的確切原因。


這是一個PowerPC上的完整系統調用!

<!--
### x86 system calls

Below we have the same interface as implemented for the x86 processor.

> Example 4.3. x86 system call example

132/5000  
-->

### x86系統調用


下面是為x86處理器實現的接口。


> 4.3的例子。x86系統調用示例

```c
/* user-visible error numbers are in the range -1 - -124: see <asm-i386/errno.h> */

#define __syscall_return(type, res)				\
do {								\
        if ((unsigned long)(res) >= (unsigned long)(-125)) {	\
                errno = -(res);					\
                res = -1;					\
        }							\
        return (type) (res);					\
} while (0)

/* XXX - _foo needs to be __foo, while __NR_bar could be _NR_bar. */
#define _syscall0(type,name)			\
type name(void)					\
{						\
long __res;					\
__asm__ volatile ("int $0x80"			\
        : "=a" (__res)				\
        : "0" (__NR_##name));			\
__syscall_return(type,__res);
}

#define _syscall1(type,name,type1,arg1)			\
type name(type1 arg1)					\
{							\
long __res;						\
__asm__ volatile ("int $0x80"				\
        : "=a" (__res)					\
        : "0" (__NR_##name),"b" ((long)(arg1)));	\
__syscall_return(type,__res);
}

#define _syscall2(type,name,type1,arg1,type2,arg2)			\
type name(type1 arg1,type2 arg2)					\
{									\
long __res;								\
__asm__ volatile ("int $0x80"						\
        : "=a" (__res)							\
        : "0" (__NR_##name),"b" ((long)(arg1)),"c" ((long)(arg2)));	\
__syscall_return(type,__res);
}

#define _syscall3(type,name,type1,arg1,type2,arg2,type3,arg3)		\
type name(type1 arg1,type2 arg2,type3 arg3)				\
{									\
long __res;								\
__asm__ volatile ("int $0x80"						\
        : "=a" (__res)							\
        : "0" (__NR_##name),"b" ((long)(arg1)),"c" ((long)(arg2)),	\
                  "d" ((long)(arg3)));					\
__syscall_return(type,__res);						\
}

#define _syscall4(type,name,type1,arg1,type2,arg2,type3,arg3,type4,arg4)	\
type name (type1 arg1, type2 arg2, type3 arg3, type4 arg4)			\
{										\
long __res;									\
__asm__ volatile ("int $0x80"							\
        : "=a" (__res)								\
        : "0" (__NR_##name),"b" ((long)(arg1)),"c" ((long)(arg2)),		\
          "d" ((long)(arg3)),"S" ((long)(arg4)));				\
__syscall_return(type,__res);							\
}

#define _syscall5(type,name,type1,arg1,type2,arg2,type3,arg3,type4,arg4,	\
          type5,arg5)								\
type name (type1 arg1,type2 arg2,type3 arg3,type4 arg4,type5 arg5)		\
{										\
long __res;									\
__asm__ volatile ("int $0x80"							\
        : "=a" (__res)								\
        : "0" (__NR_##name),"b" ((long)(arg1)),"c" ((long)(arg2)),		\
          "d" ((long)(arg3)),"S" ((long)(arg4)),"D" ((long)(arg5)));		\
__syscall_return(type,__res);							\
}

#define _syscall6(type,name,type1,arg1,type2,arg2,type3,arg3,type4,arg4,			\
          type5,arg5,type6,arg6)								\
type name (type1 arg1,type2 arg2,type3 arg3,type4 arg4,type5 arg5,type6 arg6)			\
{												\
long __res;											\
__asm__ volatile ("push %%ebp ; movl %%eax,%%ebp ; movl %1,%%eax ; int $0x80 ; pop %%ebp"	\
        : "=a" (__res)										\
        : "i" (__NR_##name),"b" ((long)(arg1)),"c" ((long)(arg2)),				\
          "d" ((long)(arg3)),"S" ((long)(arg4)),"D" ((long)(arg5)),				\
          "0" ((long)(arg6)));									\
__syscall_return(type,__res);									\
}
```
<!--
The x86 architecture is very different from the PowerPC that we looked at previously. The x86 is classed as a CISC processor as opposed to the RISC PowerPC, and has dramatically less registers.

Start by looking at the most simple _syscall0 macro. It simply calls the int instruction with a value of 0x80. This instruction makes the CPU raise interrupt 0x80, which will jump to code that handles system calls in the kernel.

We can start inspecting how to pass arguments with the longer macros. Notice how the PowerPC implementation cascaded macros downwards, adding one argument per time. This implementation has slightly more copied code, but is a little easier to follow.

x86 register names are based around letters, rather than the numerical based register names of PowerPC. We can see from the zero argument macro that only the A register gets loaded; from this we can tell that the system call number is expected in the EAX register. As we start loading registers in the other macros you can see the short names of the registers in the arguments to the `__asm__` call.

We see something a little more interesting in __syscall6, the macro taking 6 arguments. Notice the push and pop instructions? These work with the stack on x86, "pushing" a value onto the top of the stack in memory, and popping the value from the stack back into memory. Thus in the case of having six registers we need to store the value of the ebp register in memory, put our argument in in (the mov instruction), make our system call and then restore the original value into ebp. Here you can see the disadvantage of not having enough registers; stores to memory are expensive so the more you can avoid them, the better.

Another thing you might notice there is nothing like the memory fence instruction we saw previously with the PowerPC. This is because on x86 the effect of all instructions will be guaranteed to be visible when the complete. This is easier for the compiler (and programmer) to program for, but offers less flexibility.

The only thing left to contrast is the return value. On the PowerPC we had two registers with return values from the kernel, one with the value and one with an error code. However on x86 we only have one return value that is passed into __syscall_return. That macro casts the return value to unsigned long and compares it to an (architecture and kernel dependent) range of negative values that might represent error codes (note that the errno value is positive, so the negative result from the kernel is negated). However, this means that system calls can not return small negative values, since they are indistinguishable from error codes. Some system calls that have this requirement, such as getpriority(), add an offset to their return value to force it to always be positive; it is up to the userspace to realise this and subtract this constant value to get back to the "real" value.
-->
x86體系結構與我們前面看到的PowerPC非常不同。x86被歸類為與RISC PowerPC相對的CISC處理器，並且擁有非常少的寄存器。


首先查看最簡單的_syscall0宏。它只調用值為0x80的int指令。這條指令使CPU raise interrupt 0x80，該中斷將跳轉到處理內核中的系統調用的代碼。


我們可以開始檢查如何用較長的宏傳遞參數。注意PowerPC實現是如何向下級聯宏的，每次添加一個參數。這個實現有更多的複製代碼，但是更容易理解。


x86寄存器名稱基於字母，而不是基於PowerPC的數字寄存器名稱。我們可以從zero參數宏中看到只有一個寄存器被加載;從這裡我們可以看出，系統調用號預計在EAX寄存器中。當我們開始在其他宏中加載寄存器時，您可以在“__asm__”調用的參數中看到寄存器的簡短名稱。


我們在__syscall6中看到了一些更有趣的東西，即包含6個參數的宏。注意到推送和彈出指令了嗎?這些操作可以在x86上使用堆棧，將值“推”到內存中的堆棧頂部，並將值從堆棧彈出到內存中。因此，在有6個寄存器的情況下，我們需要將ebp寄存器的值存儲在內存中，將參數放入(mov指令)中，進行系統調用，然後將原始值恢復到ebp。在這裡，您可以看到沒有足夠的寄存器的缺點;存儲內存是昂貴的，所以你越能避免它們，就越好。


另一件你可能會注意到的事情是沒有什麼像我們之前在PowerPC上看到的內存圍欄指令。這是因為在x86上，所有指令的效果都將保證在完成時可見。這對於編譯器(和程序員)來說更容易編程，但是提供了更少的靈活性。


唯一需要對比的是返回值。在PowerPC上，我們有兩個寄存器，其中一個寄存器帶有內核返回的值，另一個寄存器帶有錯誤代碼。但是在x86上，我們只有一個返回值傳遞給__syscall_return。該宏將返回值轉換為無符號long，並將其與可能表示錯誤代碼的(體系結構和內核相關的)負值範圍進行比較(注意errno值為正，因此內核的負結果為負)。但是，這意味著系統調用不能返回小的負值，因為它們與錯誤代碼無法區分。一些具有此需求的系統調用，例如getpriority()，會為它們的返回值添加一個偏移量，以強制它始終為正數;用戶空間需要意識到這一點，並減去這個常量值，才能回到“真實”值。

<!--
## Privileges

### Hardware

We mentioned how one of the major tasks of the operating system is to implement security; that is to not allow one application or user to interfere with any other that is running in the system. This means applications should not be able to overwrite each others memory or files, and only access system resources as dictated by system policy.

However, when an application is running it has exclusive use of the processor. We see how this works when we examine processes in the next chapter. Ensuring the application only accesses memory it owns is implemented by the virtual memory system, which we examine in the chapter after next. The essential point is that the hardware is responsible for enforcing these rules.

The system call interface we have examined is the gateway to the application getting to system resources. By forcing the application to request resources through a system call into the kernel, the kernel can enforce rules about what sort of access can be provided. For example, when an application makes an open() system call to open a file on disk, it will check the permissions of the user against the file permissions and allow or deny access.

### Privilege Levels
Hardware protection can usually be seen as a set of concentric rings around a core set of operations.

> Figure 4.3. Rings
-->
## 特權


### 硬件


我們提到了操作系統的主要任務之一是實現安全性;也就是說，不允許一個應用程序或用戶干擾系統中運行的其他應用程序或用戶。這意味著應用程序不能相互覆蓋內存或文件，只能訪問系統策略指定的系統資源。


但是，當應用程序運行時，它只使用處理器。我們將在下一章討論過程時看到它是如何工作的。確保應用程序只訪問它所擁有的內存是由虛擬內存系統實現的，我們將在下一章中對此進行研究。關鍵是硬件負責執行這些規則。


我們研究的系統調用接口是應用程序獲取系統資源的網關。通過強制應用程序通過系統調用請求內核中的資源，內核可以強制執行關於可以提供何種訪問的規則。例如，當應用程序發出open()系統調用來打開磁碟上的文件時，它將根據文件權限檢查用戶的權限，並允許或拒絶訪問。


### 特權級別

硬件保護通常可以看作是圍繞一組核心操作的一組同心環。


> 圖4.3。環

![](http://www.bottomupcs.com/chapter03/figures/priv.png)

<!--
> Privilege levels on x86

In the inner most ring are the most protected instructions; those that only the kernel should be allowed to call. For example, the HLT instruction to halt the processor should not be allowed to be run by a user application, since it would stop the entire computer from working. However, the kernel needs to be able to call this instruction when the computer is legitimately shut down.[11]

Each inner ring can access any instructions protected by a further out ring, but not any protected by a further in ring. Not all architectures have multiple levels of rings as above, but most will either provide for at least a "kernel" and "user" level.

### 386 protection model
The 386 protection model has four rings, though most operating systems (such as Linux and Windows) only use two of the rings to maintain compatibility with other architectures that do now allow as many discrete protection levels.

386 maintains privileges by making each piece of application code running in the system have a small descriptor, called a code descriptor, which describes, amongst other things, its privilege level. When running application code makes a jump into some other code outside the region described by its code descriptor, the privilege level of the target is checked. If it is higher than the currently running code, the jump is disallowed by the hardware (and the application will crash).

### Raising Privilege
Applications may only raise their privilege level by specific calls that allow it, such as the instruction to implement a system call. These are usually referred to as a call gate because they function just as a physical gate; a small entry through an otherwise impenetrable wall. When that instruction is called we have seen how the hardware completely stops the running application and hands control over to the kernel. The kernel must act as a gatekeeper; ensuring that nothing nasty is coming through the gate. This means it must check system call arguments carefully to make sure it will not be fooled into doing anything it shouldn't (if it can be, that is a security bug). As the kernel runs in the innermost ring, it has permissions to do any operation it wants; when it is finished it will return control back to the application which will again be running with its lower privilege level.

### Fast System Calls
One problem with traps as described above is that they are very expensive for the processor to implement. There is a lot of state to be saved before context can switch. Modern processors have realised this overhead and strive to reduce it.

To understand the call-gate mechanism described above requires investigation of the ingenious but complicated segmentation scheme used by the processor. The original reason for segmentation was to be able to use more than the 16 bits available in a register for an address, as illustrated in Figure 4.4, “x86 Segmentation Addressing”.

> Figure 4.4. x86 Segmentation Addressing
-->

> 特權級別


在最裡面的環是最受保護的指令;只允許內核調用的那些。例如，停止處理器的HLT指令不應該被允許由用戶應用程序運行，因為它將停止整個計算機的工作。但是，內核需要能夠在計算機合法關閉時調用該指令。[11]


每個內環都可以訪問任何由進一步的外環保護的指令，但不能訪問任何由進一步的內環保護的指令。並不是所有體系結構都像上面那樣具有多個級別的環，但是大多數體系結構都至少提供一個“內核”和“用戶”級別。


### 386保護模式

386保護模型有4個環，儘管大多數操作系統(如Linux和Windows)只使用其中的兩個環來維護與其他體系結構的兼容性，而其他體系結構現在允許同樣多的離散保護級別。


386通過使系統中運行的每段應用程序代碼都有一個稱為代碼描述符的小描述符來維護特權，該描述符描述了系統的特權級別。當運行應用程序代碼跳轉到其代碼描述符描述的區域之外的其他代碼時，會檢查目標的特權級別。如果跳轉高於當前運行的代碼，則硬件不允許跳轉(應用程序將崩潰)。


### 提高特權

應用程序只能通過允許它的特定調用(如實現系統調用的指令)來提高其權限級別。這些通常被稱為調用門，因為它們的功能就像物理門;通過一堵否則無法穿透的牆的一個小入口。當這個指令被調用時，我們已經看到硬件是如何完全停止運行應用程序並將控制權交給內核的。內核必須充當看門人;確保沒有討厭的東西從大門進來。這意味著它必須仔細檢查系統調用參數，以確保它不會被騙去做任何它不應該做的事情(如果可以的話，這是一個安全漏洞)。當內核運行在最內環時，它有權限執行它想要的任何操作;當它完成時，它將把控制權返回給應用程序，應用程序將再次以較低的權限級別運行。


### 快速系統調用

如上所述的陷阱的一個問題是，它們對於處理器實現來說非常昂貴。在上下文切換之前需要保存很多狀態。現代處理器已經意識到這種開銷，並努力減少它。


要理解上述調用門機制，需要研究處理器使用的巧妙而複雜的分割方案。分割的最初原因是能夠使用寄存器中的16位以上的地址，如圖4.4所示，“x86分割定址”。


>圖4.4。x86分割處理

![](http://www.bottomupcs.com/chapter03/figures/ia32-segmentation.png)

<!--
Segmentation expanding the address space of a processor by dividing it into chunks. The processor keeps special segment registers, and addresses are specified by a segment register and offset combination. The value of the segment register is added to the offset portion to find a final address.


When x86 moved to 32 bit registers, the segmentation scheme remained but in a different format. Rather than fixed segment sizes, segments are allowed to be any size. This means the processor needs to keep track of all these different segments and their sizes, which it does using descriptors. The segment descriptors available to everyone are kept in the global descriptor table or GDT for short. Each process has a number of registers which point to entries in the GDT; these are the segments the process can access (there are also local descriptor tables, and it all interacts with task state segments, but that's not important now). The overall situation is illustrated in Figure 4.5, “x86 segments”.

> Figure 4.5. x86 segments
-->
分割通過將處理器分割成塊來擴展其地址空間。處理器保留特殊的段寄存器，地址由段寄存器和偏移量組合指定。段寄存器的值被添加到偏移部分以找到最終地址。



當x86遷移到32位寄存器時，分割方案仍然保留，但是格式不同。而不是固定的段大小，段被允許是任何大小。這意味著處理器需要跟蹤所有這些不同的段和它們的大小，它使用描述符進行跟蹤。每個人都可以使用的段描述符都保存在全局描述符表或GDT中。每個進程都有一些寄存器，這些寄存器指向GDT中的條目;這些是流程可以訪問的段(還有本地描述符表，它們都與任務狀態段交互，但現在不重要了)。總體情況如圖4.5“x86段”所示。


>圖4.5。x86段

![](http://www.bottomupcs.com/chapter03/figures/ia32-segments.png)

<!--
> x86 segments in action. Notice how a "far-call" passes via a call-gate which redirects to a segment of code running at a lower ring level. The only way to modify the code-segment selector, implicitly used for all code addresses, is via the call mechanism. Thus the call-gate mechanism ensures that to choose a new segment descriptor, and hence possibly change protection levels, you must transition via a known entry point.

Since the operating system assigns the segment registers as part of the process state, the processor hardware knows what segments of memory the currently running process can access and can enforce protection to ensure the process doesn't touch anything it is not supposed to. If it does go out of bounds, you receive a segmentation fault, which most programmers are familiar with.

The picture becomes more interesting when running code needs to make calls into code that resides in another segment. As discussed in the section called “386 protection model”, x86 does this with rings, where ring 0 is the highest permission, ring 3 is the lowest, and inner rings can access outer rings but not vice-versa.

As discussed in the section called “Raising Privilege”, when ring 3 code wants to jump into ring 0 code, it is essentially modifying its code segment selector to point to a different segment. To do this, it must use a special far-call instruction which hardware ensures passes through the call gate. There is no other way for the running process to choose a new code-segment descriptor, and hence the processor will start executing code at the known offset within the ring 0 segment, which is responsible for maintaining integrity (e.g. not reading arbitrary and possibly malicious code and executing it. Of course nefarious attackers will always look for ways to make your code do what you did not intend it to!).

This allows a whole hierarchy of segments and permissions between them. You might have noticed a cross segment call sounds exactly like a system call. If you've ever looked at Linux x86 assembly the standard way to make a system call is int 0x80, which raises interrupt 0x80. An interrupt stops the processor and goes to an interrupt gate, which then works the same as a call gate -- it changes privilege level and bounces you off to some other area of code .

The problem with this scheme is that it is slow. It takes a lot of effort to do all this checking, and many registers need to be saved to get into the new code. And on the way back out, it all needs to be restored again.

On a modern x86 system segmentation and the four-level ring system is not used thanks to virtual memory, discussed fully in Chapter 6, Virtual Memory. The only thing that really happens with segmentation switching is system calls, which essentially switch from mode 3 (userspace) to mode 0 and jump to the system call handler code inside the kernel. Thus the processor provides extra fast system call instructions called sysenter (and sysexit to get back) which speed up the whole process over a int 0x80 call by removing the general nature of a far-call — that is the possibility of transitioning into any segment at any ring level — and restricting the call to only transition to ring 0 code at a specific segment and offset, as stored in registers.

Because the general nature has been replaced with so much prior-known information, the whole process can be speed up, and hence we have a the aforementioned fast system call. The other thing to note is that state is not preserved when the kernel gets control. The kernel has to be careful to not to destroy state, but it also means it is free to only save as little state as is required to do the job, so can be much more efficient about it. This is a very RISC philosophy, and illustrates how the line blurs between RISC and CISC processors.

For more information on how this is implemented in the Linux kernel, see the section called “Kernel Library”.
-->

> x86段。請注意“遠調用”是如何通過調用門的，該調用門重定向到運行在較低環級別的代碼段。修改代碼段選擇器(隱式地用於所有代碼地址)的唯一方法是通過調用機制。因此，調用門機制確保要選擇一個新的段描述符，並因此可能更改保護級別，您必須通過一個已知的入口點進行轉換。


由於操作系統將段寄存器指定為進程狀態的一部分，因此處理器硬件知道當前正在運行的進程可以訪問哪些內存段，並可以實施保護，以確保進程不訪問任何不應該訪問的內存段。如果它確實超出了範圍，您將收到一個分段錯誤，這是大多數程序員都熟悉的。


當運行代碼需要對駐留在另一個段中的代碼進行調用時，圖形變得更加有趣。正如在“386保護模型”一節中所討論的，x86在環上可以做到這一點，環0是最高權限，環3是最低權限，內環可以訪問外環，反之亦然。


正如在“提升特權”一節中所討論的，當環3代碼想要跳轉到環0代碼時，它本質上是修改它的代碼段選擇器以指向不同的段。要做到這一點，它必須使用一種特殊的遠程調用指令，硬件確保通過調用門。運行的進程沒有其他方法來選擇新的代碼段描述符，因此處理器將在環0段內的已知偏移量處開始執行代碼，該偏移量負責維護完整性(例如，不讀取任意且可能惡意的代碼並執行它)。當然，邪惡的攻擊者總是會想方設法讓你的代碼做你不想做的事情!


這允許段之間的層次結構和權限。您可能已經注意到交叉段調用聽起來完全像系統調用。如果您曾經看過Linux x86程序集，那麼進行系統調用的標準方法是int 0x80，這會引發中斷0x80。中斷停止處理器併進入中斷門，中斷門的工作原理與調用門相同——它改變了權限級別並將您跳轉到其他代碼區域。


這個方案的問題是速度太慢。完成所有這些檢查需要花費很多精力，而且需要保存許多寄存器才能進入新代碼。在回去的路上，一切都需要重新恢復。


在現代x86系統上，由於虛擬內存的原因，沒有使用四層環系統，在第6章“虛擬內存”中進行了詳細討論。分割交換中真正發生的事情是系統調用，它本質上是從模式3(用戶空間)切換到模式0，然後跳到內核內部的系統調用處理程序代碼。因此快速處理器提供了額外的系統調用指令稱為sysenter(和sysexit回到),加快整個過程在一個int 0 x80調用通過移除的一般性far-call——這是過渡到任何的可能性在任何環段水平,限制調用只是過渡環0代碼在一個特定段和偏移量,存儲在寄存器中。


因為一般的性質已經被這麼多預先知道的信息所取代，整個過程可以加速，因此我們有了前面提到的快速系統調用。另一件需要注意的事情是，當內核獲得控制時，狀態不會被保留。內核必須小心不要破壞狀態，但這也意味著它可以自由地只保存執行任務所需的最少的狀態，因此可以更有效地處理它。這是一個非常RISC的哲學，並說明了RISC和CISC處理器之間的界限是如何模糊的。


有關如何在Linux內核中實現此功能的更多信息，請參閱“內核庫”一節。

<!--
### Other ways of communicating with the kernel

### ioctl
about ioctls

### File Systems
about proc, sysfs, debugfs, etc
-->